{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from dateutil.parser import parse\n",
    "from datetime import timedelta\n",
    "import requests\n",
    "import math\n",
    "import unicodecsv as csv\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n* relevant: whether Heajin classified the particular statement as relevant or irrelevant. 1 indicates that the statement is relevant, while 0 indicates that it is not.\\n* k_relevant: whether Dr. Kreps classified the particular statement as relevant or irrelevant. 1 indicates that the statement is relevant, while 0 indicates that it is not.\\n* house: whether or not the legislator is a member of the House of Representatives at the time of the statement. 1 indicates they are a member of the House, 0 indicates they are a member of the Senate. Blank values indicate that the data is either not known or that they are a member of neither (speaker, etc).\\n* sex: the sex of the legislator, according to the United States legislator biography project.\\n* days_since_last_strike: the number of days that have elapsed since the most recent drone strike. Data is retrieved from https://tbij.dronescout.org, which is itself an interface for the Bureau of Investigative Journalism\\xe2\\x80\\x99s data.\\n* last_name: the last name of the legislator who made the statement.\\n* dim_1: the 1st dimension DW-NOMINATE constant space score for the legislator.\\n* dim_2: the 2nd dimension DW-NOMINATE constant space score for the legislator.\\n* id: the ID of the statement (calculated by finding the MD5 hash of the date, text, document title, and speaker last name appended to one another, see `annotate.py` for implementation).\\n* first_name: the first name of the legislator.\\n* k_sentiment: the sentiment, as classified by Dr. Kreps. 1 indicates pro-drone, 0 indicates neutral, and -1 anti-drone/restricting statements.\\n* icpsr: the ICPSR legislator code.\\n* general_sentiment: the statement\\xe2\\x80\\x99s general outlook toward drones. 1 indicates a statement that is pro-drones, 0 indicates a statement that is neutral, and -1 indicates a statement that is anti-drones.\\n* state: the first seven letters of the legislator\\xe2\\x80\\x99s state.\\n* statement: the raw text of the statement, as recorded in the Congressional Record.\\n* party: the legislator\\xe2\\x80\\x99s party. 0 indicates Democrats, 1 indicates Republicans.\\n* filibuster: whether the statement was made during Rand Paul\\xe2\\x80\\x99s drone filibuster.\\n* congress: the Congress that the statement was made in.\\n* days_until_term_ends: the number of days until the legislator is up for reelection.\\n* loyalty: whether the legislator\\xe2\\x80\\x99s party is the same as the President. 1 if true, 0 otherwise.\\n* date: the date the statement was made.\\n* state_code: the ICPSR state code.\\n* dronebase: whether or not the legislator has a drone base in their home state. 0 if no, 1 if yes but without Predator/Reaper, 2 if with Predator/Reaper\\n* categories: the Python-object encoded categories, as classified by Heajin\\n* strike_recently: whether a drone strike took place within the week previous to the statement being made\\n* votes: the number of votes considered in the DW-NOMINATE score of the legislator\\n* k_restraining: whether the statement was classified by Dr. Kreps as restraining. 1 indicates statements that are restraining, while 0 indicates those that aren't.\\n* periphery: the standard deviations from the party norm, where positive values indicate more partisan tendencies and negative values indicate more moderate tendencies\\n* unsigned_periphery: the unsigned (absolute value) periphery score\\n* restraining: 1 if the general sentiment is -1, 0 if not, and None if general sentiment is not known\\n* seniority: the number of congresses the legislator has served in, including the current congress, at the time of the statement\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "* relevant: whether Heajin classified the particular statement as relevant or irrelevant. 1 indicates that the statement is relevant, while 0 indicates that it is not.\n",
    "* k_relevant: whether Dr. Kreps classified the particular statement as relevant or irrelevant. 1 indicates that the statement is relevant, while 0 indicates that it is not.\n",
    "* house: whether or not the legislator is a member of the House of Representatives at the time of the statement. 1 indicates they are a member of the House, 0 indicates they are a member of the Senate. Blank values indicate that the data is either not known or that they are a member of neither (speaker, etc).\n",
    "* sex: the sex of the legislator, according to the United States legislator biography project.\n",
    "* days_since_last_strike: the number of days that have elapsed since the most recent drone strike. Data is retrieved from https://tbij.dronescout.org, which is itself an interface for the Bureau of Investigative Journalism’s data.\n",
    "* last_name: the last name of the legislator who made the statement.\n",
    "* dim_1: the 1st dimension DW-NOMINATE constant space score for the legislator.\n",
    "* dim_2: the 2nd dimension DW-NOMINATE constant space score for the legislator.\n",
    "* id: the ID of the statement (calculated by finding the MD5 hash of the date, text, document title, and speaker last name appended to one another, see `annotate.py` for implementation).\n",
    "* first_name: the first name of the legislator.\n",
    "* k_sentiment: the sentiment, as classified by Dr. Kreps. 1 indicates pro-drone, 0 indicates neutral, and -1 anti-drone/restricting statements.\n",
    "* icpsr: the ICPSR legislator code.\n",
    "* general_sentiment: the statement’s general outlook toward drones. 1 indicates a statement that is pro-drones, 0 indicates a statement that is neutral, and -1 indicates a statement that is anti-drones.\n",
    "* state: the first seven letters of the legislator’s state.\n",
    "* statement: the raw text of the statement, as recorded in the Congressional Record.\n",
    "* party: the legislator’s party. 0 indicates Democrats, 1 indicates Republicans.\n",
    "* filibuster: whether the statement was made during Rand Paul’s drone filibuster.\n",
    "* congress: the Congress that the statement was made in.\n",
    "* days_until_term_ends: the number of days until the legislator is up for reelection.\n",
    "* loyalty: whether the legislator’s party is the same as the President. 1 if true, 0 otherwise.\n",
    "* date: the date the statement was made.\n",
    "* state_code: the ICPSR state code.\n",
    "* dronebase: whether or not the legislator has a drone base in their home state. 0 if no, 1 if yes but without Predator/Reaper, 2 if with Predator/Reaper\n",
    "* categories: the Python-object encoded categories, as classified by Heajin\n",
    "* strike_recently: whether a drone strike took place within the week previous to the statement being made\n",
    "* votes: the number of votes considered in the DW-NOMINATE score of the legislator\n",
    "* k_restraining: whether the statement was classified by Dr. Kreps as restraining. 1 indicates statements that are restraining, while 0 indicates those that aren't.\n",
    "* periphery: the standard deviations from the party norm, where positive values indicate more partisan tendencies and negative values indicate more moderate tendencies\n",
    "* unsigned_periphery: the unsigned (absolute value) periphery score\n",
    "* restraining: 1 if the general sentiment is -1, 0 if not, and None if general sentiment is not known\n",
    "* seniority: the number of congresses the legislator has served in, including the current congress, at the time of the statement\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addl_fields = {}\n",
    "with open(\"/Users/miles/Source/combine-cr/data/sr2.json\", \"r\") as datain:\n",
    "    for mention in json.load(datain):\n",
    "        addl_fields[mention['id']] = mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD AND COMBINE CLASSIFICATIONS\n",
    "classifications = {}\n",
    "with open(\"/Users/miles/Source/combine-cr/data/kreps_classifications.json\", \"r\") as datain:\n",
    "    for element in json.load(datain): # is array\n",
    "        classifications[element['ID']] = {\n",
    "            \"k_relevant\": element['RELEVANT'],\n",
    "            \"k_sentiment\": element['CATEGORICAL SENTIMENT']\n",
    "        }\n",
    "with open(\"/Users/miles/Source/combine-cr/data/detailed_classifications.csv\", \"r\") as datain:\n",
    "    r = csv.reader(datain)\n",
    "    first = True\n",
    "    for row in r:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        relevant_str = row[0].strip()\n",
    "        categories_str = row[1].strip()\n",
    "        categorical_sentiments_str = row[2].strip()\n",
    "        general_sentiment_str = row[3].strip()\n",
    "        id_str = row[5].strip()\n",
    "        \n",
    "        # make categories dictionary\n",
    "        categories = {}\n",
    "        sentiments = categorical_sentiments_str.split(\",\")\n",
    "        i = 0\n",
    "        for category in categories_str.split(\",\"):\n",
    "            if category == \"TRANSPARENCY\":\n",
    "                category = \"DISCLOSURE\" # the two were used interchangably\n",
    "            try:\n",
    "                categories[category.strip()] = {\n",
    "                    \"ANTI\": -1,\n",
    "                    \"NEUTRAL\": 0,\n",
    "                    \"PRO\": 1,\n",
    "                }[sentiments[i].strip().upper()]\n",
    "            except:\n",
    "                #print categorical_sentiments_str\n",
    "                #print categories_str\n",
    "                #print id_str\n",
    "                pass\n",
    "            i += 1\n",
    "            \n",
    "        # parse classifications\n",
    "        relevant = relevant_str == \"RELEVANT\" # later, this is normalized into 1 and 0\n",
    "        general_sentiment = None\n",
    "        if general_sentiment_str in [\"PRO\", \"ANTI\", \"NEUTRAL\"]:\n",
    "            general_sentiment = {\n",
    "                \"PRO\": 1,\n",
    "                \"NEUTRAL\": 0,\n",
    "                \"ANTI\": -1\n",
    "            }[general_sentiment_str]\n",
    "        \n",
    "        # push into main classification tracking object\n",
    "        classifications[id_str][\"general_sentiment\"] = general_sentiment\n",
    "        classifications[id_str][\"categories\"] = categories\n",
    "        classifications[id_str][\"relevant\"] = relevant # later, this is normalized into 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_congress(time):\n",
    "    time = time - timedelta(days=3)\n",
    "    year = time.year\n",
    "    return int(math.ceil(0.5*year - 894))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mentions = {}\n",
    "with open(\"/Users/miles/Source/combine-cr/data/mentions.json\", \"r\") as datain:\n",
    "    for element in json.load(datain): # is array\n",
    "        mentions[element['ID']] = {\n",
    "            \"id\": element['ID'],\n",
    "            \"k_relevant\": classifications[element['ID']][\"k_relevant\"],\n",
    "            \"k_sentiment\": classifications[element['ID']][\"k_sentiment\"],\n",
    "            \"categories\": classifications[element['ID']][\"categories\"],\n",
    "            \"general_sentiment\": classifications[element['ID']][\"general_sentiment\"],\n",
    "            \"relevant\": classifications[element['ID']][\"relevant\"],\n",
    "            \"date\": element['DATE'],\n",
    "            \"date_parsed\": parse(element['DATE']),\n",
    "            \"title\": element['TITLE'],\n",
    "            \"first_name\": element['FIRST NAME'],\n",
    "            \"last_name\": element['LAST NAME'],\n",
    "            \"party\": element['PARTY'],\n",
    "            \"sex\": element['SEX'],\n",
    "            \"state\": element['STATE'],\n",
    "            \"statement\": element['STATEMENT'],\n",
    "            \"congress\": get_congress(parse(element['DATE']))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strikes = [strike for strike in requests.get(\"https://tbij.dronescout.org/data\").json().itervalues() if not isinstance(strike, str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strikedates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for strike in strikes:\n",
    "    try:\n",
    "        if not strike['location'].endswith(\"Afghanistan\"):\n",
    "            strikedates.append(parse(strike['date']))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strikedates = sorted(strikedates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(strikedates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restrictive_mentions_by_year = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for mention in mentions.itervalues():\n",
    "    latest_strike = None\n",
    "    for strikedate in strikedates:\n",
    "        if strikedate > mention['date_parsed']:\n",
    "            break\n",
    "        latest_strike = strikedate\n",
    "    days_since_strike = None\n",
    "    if latest_strike is not None:\n",
    "        days_since_strike = (mention['date_parsed'] - latest_strike).days\n",
    "    mention['days_since_strike'] = days_since_strike\n",
    "    syear = str(mention['date_parsed'].year)\n",
    "    if syear not in restrictive_mentions_by_year:\n",
    "        restrictive_mentions_by_year[syear] = 0\n",
    "    if mention['relevant'] == \"Y\" and mention[\"sentiment\"] == \"Anti\":\n",
    "        restrictive_mentions_by_year[syear] += 1\n",
    "#     print mention['date']\n",
    "#     print days_since_strike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"2000\": 0, \"2001\": 0, \"2002\": 0, \"2003\": 0, \"2004\": 0, \"2005\": 0, \"2006\": 0, \"2007\": 0, \"2008\": 0, \"2009\": 0, \"2010\": 0, \"2011\": 0, \"2012\": 0, \"2013\": 0, \"2014\": 0, \"2015\": 0, \"2016\": 0, \"2017\": 0}\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print json.dumps(restrictive_mentions_by_year, sort_keys=True)\n",
    "print sum(restrictive_mentions_by_year.itervalues())\n",
    "print len([\n",
    "    mention for mention in mentions.itervalues() \n",
    "    if mention['relevant'] == \"Y\" \n",
    "    and mention['sentiment'] == \"Anti\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "# ADD DW-NOMINATE TO THE DATASET\n",
    "\n",
    "def decode_dw_row(row):\n",
    "    # decodes row such as:\n",
    "    #  114   29774  71  24  CALIFOR    100  0  1   CAPPS         -0.389   -0.227      -81.84920   1077     26    0.927\n",
    "    # format: congress, icpsr, state code, district number (0 if senate or president), state name, party code (100=dem, 200=republican), occupancy, office attainment type, name, 1st dimension coord, 2nd dimension coord, log likelyhood, # of votes, # of classification errors, geometric mean probability\n",
    "    elements = [element.strip() for element in row.split(\"  \") if element.strip() != \"\"]\n",
    "    if len(elements) == 16:\n",
    "        del elements[9]\n",
    "    if len(elements) != 15:\n",
    "        print \"error: != 15 elements in a row! {}\".format(len(elements))\n",
    "        print row\n",
    "        raise Exception(\"!= 15 elements in row\")\n",
    "    return {\n",
    "        \"latest_congress\": elements[0],\n",
    "        \"icpsr\": elements[1],\n",
    "        \"state_code\": elements[2],\n",
    "        \"district_number\": elements[3],\n",
    "        \"state\": elements[4],\n",
    "        \"party_code\": int(elements[5]),\n",
    "        \"occupancy\": elements[6],\n",
    "        \"office_attainment_type\": elements[7],\n",
    "        \"last_name\": elements[8].split(\" \")[0],\n",
    "        \"dim_1\": float(elements[9]),\n",
    "        \"dim_2\": float(elements[10]),\n",
    "        \"log_likelyhood\": float(elements[11]),\n",
    "        \"votes\": int(elements[12]),\n",
    "        \"classification_errors\": float(elements[13]),\n",
    "        \"geometric_mean_probability\": float(elements[14])\n",
    "    }\n",
    "dw_nominate_scores = {}\n",
    "raw_legislators = []\n",
    "_already_included_legislators = []\n",
    "minimum_congress = 106\n",
    "terms = {}\n",
    "with open(\"/Users/miles/Source/combine-cr/data/DW-NOMINATE.txt\", \"r\") as dw:\n",
    "    for row in dw.readlines():\n",
    "        dat = decode_dw_row(row)\n",
    "        if int(dat['latest_congress']) < 106:\n",
    "            continue\n",
    "        party = \"\"\n",
    "        if dat['party_code'] == 100:\n",
    "            party = \"Democrat\"\n",
    "        if dat['party_code'] == 200:\n",
    "            party = \"Republican\"\n",
    "        dat[\"party\"] = party\n",
    "        name = dat['last_name'] + dat['state'] + str(dat['latest_congress'])\n",
    "        dw_nominate_scores[name.lower()] = dat\n",
    "        if dat['icpsr'] not in _already_included_legislators and dat['latest_congress'] >= minimum_congress:\n",
    "            raw_legislators.append(dat)\n",
    "            _already_included_legislators.append(dat['icpsr'])\n",
    "        \n",
    "        if dat['icpsr'] not in terms:\n",
    "            terms[dat['icpsr']] = []\n",
    "        if int(dat['latest_congress']) not in terms[dat['icpsr']]:\n",
    "            terms[dat['icpsr']].append(int(dat['latest_congress']))\n",
    "\n",
    "print len(raw_legislators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_seniority(time, legislator):\n",
    "    congress = get_congress(time)\n",
    "    terms_served = terms[legislator['icpsr']]\n",
    "    count = 0\n",
    "    for term in terms_served:\n",
    "        if term <= congress:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "republican_std_dev = numpy.std([legislator[\"dim_1\"] for legislator in raw_legislators if legislator[\"party_code\"] == 200])\n",
    "democrat_std_dev = numpy.std([legislator[\"dim_1\"] for legislator in raw_legislators if legislator[\"party_code\"] == 100])\n",
    "\n",
    "republican_mean = numpy.mean([legislator[\"dim_1\"] for legislator in raw_legislators if legislator[\"party_code\"] == 200])\n",
    "democrat_mean = numpy.mean([legislator[\"dim_1\"] for legislator in raw_legislators if legislator[\"party_code\"] == 100])\n",
    "\n",
    "def periphery(legislator):\n",
    "    if \"party_code\" not in legislator:\n",
    "        return None # legislator not known\n",
    "    if legislator[\"party_code\"] not in [100, 200]:\n",
    "        print legislator[\"party_code\"]\n",
    "        return None\n",
    "    party_std_dev = None # not pythonic, not a problem\n",
    "    party_mean = None\n",
    "    opposite_mean = None\n",
    "    if legislator[\"party_code\"] is 200:\n",
    "        party_std_dev = republican_std_dev\n",
    "        party_mean = republican_mean\n",
    "        opposite_mean = democrat_mean\n",
    "    elif legislator[\"party_code\"] is 100:\n",
    "        party_std_dev = democrat_std_dev\n",
    "        party_mean = democrat_mean\n",
    "        opposite_mean = republican_mean\n",
    "    \n",
    "    score = abs(party_mean - legislator[\"dim_1\"]) / party_std_dev\n",
    "    \n",
    "    neg = (legislator[\"dim_1\"] < party_mean) == (opposite_mean < party_mean)\n",
    "    if neg:\n",
    "        score *= -1\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Republican standard deviation: 0.160409314961\n",
      "Democrat standard deviation: 0.139125844637\n",
      "Republican mean 1st dimension score: 0.439763665595\n",
      "Democrat mean 1st dimension score: -0.336179190751\n"
     ]
    }
   ],
   "source": [
    "print \"Republican standard deviation: \" + str(republican_std_dev)\n",
    "print \"Democrat standard deviation: \" + str(democrat_std_dev)\n",
    "print \"Republican mean 1st dimension score: \" + str(republican_mean)\n",
    "print \"Democrat mean 1st dimension score: \" + str(democrat_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print [legislator[\"last_name\"] + str(periphery(legislator)) for legislator in sorted(raw_legislators, key=lambda k: periphery(k))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MERGE DW-NOMINATE DATA WITH LEGISLATOR DATA\n",
    "for mention in mentions.itervalues():\n",
    "    name = (mention['last_name'] + mention['state'][:7] + str(get_congress(mention['date_parsed']))).lower()\n",
    "    if name in dw_nominate_scores:\n",
    "        dw_nominate_data = dw_nominate_scores[name]\n",
    "        for key in dw_nominate_data.iterkeys():\n",
    "            mention[key] = dw_nominate_data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "def get_current_executive_party(statement_date):\n",
    "    if statement_date > date(2017,1,19):\n",
    "        return 0\n",
    "    if statement_date > date(2009,1,19):\n",
    "        return 1\n",
    "    if statement_date > date(2001, 1, 19):\n",
    "        return 0\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states_1 =   [\"WASHINGTON\",\n",
    "            \"OREGON\",\n",
    "            \"MONTANA\",\n",
    "            \"MINNESOTA\",\n",
    "            \"UTAH\",\n",
    "            \"COLORADO\",\n",
    "            \"KANSAS\",\n",
    "            \"LOUISIANA\",\n",
    "            \"MISSISSIPPI\",\n",
    "            \"KENTUCKY\",\n",
    "            \"ALABAMA\",\n",
    "            \"INDIANA\",\n",
    "            \"WEST VIRGINIA\",\n",
    "            \"FLORIDA\",\n",
    "            \"VIRGINIA\",\n",
    "            \"PENNSYLVANIA\",\n",
    "            \"NORTH CAROLINA\",\n",
    "            \"MARYLAND\",\n",
    "            \"NEW JERSEY\",\n",
    "            \"NEW HAMPSHIRE\",\n",
    "            \"ARKANSAS\",\n",
    "            \"HAWAII\"]\n",
    "\n",
    "states_2 =   [\n",
    "            \"NORTH DAKOTA\",\n",
    "            \"CALIFORNIA\",\n",
    "            \"NEVADA\",\n",
    "            \"ARIZONA\",\n",
    "            \"NEW MEXICO\",\n",
    "            \"TEXAS\",\n",
    "            \"GEORGIA\",\n",
    "            \"NEW YORK\",\n",
    "            \"SOUTH DAKOTA\",\n",
    "            \"NEVADA\"]\n",
    "\n",
    "# data according to https://publicintelligence.net/dod-us-drone-activities-map/\n",
    "# states_1 is all states without predators and reapers, states_2 are those with\n",
    "\n",
    "def drone_state_status(statename):\n",
    "    statename = statename.strip()\n",
    "    if statename.lower() == \"unknown\":\n",
    "        return None\n",
    "    if statename.upper()[:7] in [state[:7] for state in states_1]:\n",
    "        return 1\n",
    "    if statename.upper()[:7] in [state[:7] for state in states_2]:\n",
    "        return 2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'DISCLOSURE', u'HUMANITARIAN', u'FOREIGNPOLICY', u'REFERENCE', u'DOMESTIC-LEGALITY', u'FINANCE', u'TECHNOLOGY', u'FOREIGNUSE', u'INTERNATIONAL-LEGALITY', u'PTSD', u'JOBS']\n"
     ]
    }
   ],
   "source": [
    "# encode CATEGORIES\n",
    "\n",
    "categories = []\n",
    "\n",
    "# find all the categories\n",
    "for z in mentions.itervalues():\n",
    "    for category in z['categories']:\n",
    "        if category not in categories:\n",
    "            categories.append(category)\n",
    "            \n",
    "print categories\n",
    "\n",
    "# create columns\n",
    "for z in mentions.itervalues():\n",
    "    for category in categories:\n",
    "        present = 0\n",
    "        sentiment = None\n",
    "        if category in z['categories']:\n",
    "            present = 1\n",
    "            sentiment = z['categories'][category]\n",
    "        z['CATEGORY_' + category] = present\n",
    "        z['CATEGORICAL_SENTIMENT_' + category] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize data that is not already normalized\n",
    "\n",
    "mentions_compiled = []\n",
    "for z in mentions.itervalues():\n",
    "    \n",
    "    if z['id'] in addl_fields:\n",
    "        z['days_until_term_ends'] = addl_fields[z['id']]['days_until_term_ends']\n",
    "\n",
    "    # party scores\n",
    "    try:\n",
    "        if z['party'] == \"Democrat\":\n",
    "            z['party'] = 1\n",
    "        elif z['party'] == \"Republican\":\n",
    "            z['party'] = 0\n",
    "        else:\n",
    "            z['party'] = None\n",
    "    except:\n",
    "        z['party'] = None\n",
    "        \n",
    "    # Kreps sentiment\n",
    "    if z['k_sentiment']:\n",
    "        if z['k_sentiment'].strip().lower() == \"anti\":\n",
    "            z['k_sentiment'] = -1\n",
    "        elif z['k_sentiment'].strip().lower() == \"pro\":\n",
    "            z['k_sentiment'] = 1\n",
    "        elif z['k_sentiment'].strip().lower() == \"neutral\":\n",
    "            z['k_sentiment'] = 0\n",
    "            \n",
    "    # restraining\n",
    "    if z['k_sentiment']:\n",
    "        if z['k_sentiment'] == 1 or z['k_sentiment'] == 0:\n",
    "            z['k_restraining'] = 0\n",
    "        if z['k_sentiment'] == -1:\n",
    "            z['k_restraining'] = 1            \n",
    "    else:\n",
    "        z['k_restraining'] = None\n",
    "        \n",
    "    # Kreps relevant scores\n",
    "    try:\n",
    "        if z['k_relevant'] == \"Y\":\n",
    "            z['k_relevant'] = 1\n",
    "        elif z['k_relevant'] == \"N\":\n",
    "            z['k_relevant'] = 0\n",
    "        else:\n",
    "            z['k_relevant'] = None\n",
    "    except e:\n",
    "        print e\n",
    "        z['k_relevant'] = None\n",
    "        \n",
    "    # relevant scores\n",
    "    try:\n",
    "        if z['relevant'] == True:\n",
    "            z['relevant'] = 1\n",
    "        elif z['relevant'] == False:\n",
    "            z['relevant'] = 0\n",
    "        else:\n",
    "            z['relevant'] = None\n",
    "    except:\n",
    "        z['relevant'] = None\n",
    "        \n",
    "    # code sex into dataset (can't code gender, not binary, though neither is sex... oh well, STATA doesn't care...)\n",
    "    try:\n",
    "        if z['sex'] == \"M\":\n",
    "            z['sex'] = 1\n",
    "        elif z['sex'] == \"F\":\n",
    "            z['sex'] = 0\n",
    "        else:\n",
    "            z['sex'] = None\n",
    "    except:\n",
    "        z['sex'] = None\n",
    "        \n",
    "    # absolute value perphery\n",
    "    z['unsigned_periphery'] = None\n",
    "    if 'periphery' in z and z['periphery'] is not None:\n",
    "        z['unsigned_periphery'] = abs(z['periphery'])\n",
    "        \n",
    "    # recent scores\n",
    "    try:\n",
    "        if z['days_since_strike'] <= 7:\n",
    "            z['strike_recently'] = 1\n",
    "        else:\n",
    "            z['strike_recently'] = 0\n",
    "    except:\n",
    "        z['strike_recently'] = None\n",
    "        \n",
    "    # loyalty\n",
    "    if 'date_parsed' in z and 'party' in z:\n",
    "        if z['party'] == get_current_executive_party(z['date_parsed'].date()):\n",
    "            z['loyalty'] = 1\n",
    "        else:\n",
    "            z['loyalty'] = 0\n",
    "    else:\n",
    "        z['loyalty'] = None\n",
    "        \n",
    "    # general restraining\n",
    "    z['restraining'] = None\n",
    "    if 'general_sentiment' in z and z['general_sentiment'] == -1:\n",
    "        z['restraining'] = 1\n",
    "    else:\n",
    "        z['restraining'] = 0\n",
    "    \n",
    "    # filibuster\n",
    "    z['filibuster'] = 0\n",
    "    if 'icpsr' in z and 'date_parsed' in z and z['icpsr'] is not None and int(z['icpsr']) == 41104 and z['date_parsed'].date() == date(2013, 3, 6): # rand paul on the day of his filibuster\n",
    "        z['filibuster'] = 1\n",
    "            \n",
    "    # party periphery\n",
    "    z['periphery'] = periphery(z)\n",
    "    \n",
    "    # legislative vulnerability\n",
    "    # todo\n",
    "        \n",
    "    # dronebase\n",
    "    if 'state' in z and z['state']:\n",
    "        z['dronebase'] = drone_state_status(z['state'])\n",
    "    else:\n",
    "        z['dronebase'] = None\n",
    "        \n",
    "    # house — somewhat unreliable for legislators who have served in both\n",
    "    if 'dim_1' in z:\n",
    "        if 'district_number' in z and z['district_number'] is not None:\n",
    "            if int(z['district_number']) != 0:\n",
    "                z['house'] = 1 # house\n",
    "            else:\n",
    "                z['house'] = 0 # senate\n",
    "    else:\n",
    "        z['house'] = None\n",
    "    \n",
    "    if 'icpsr' in z and z['icpsr'] is not None:\n",
    "        z['seniority'] = get_seniority(z['date_parsed'], z)\n",
    "    \n",
    "    # delete unneded variables\n",
    "    try:\n",
    "        del z['date_parsed']\n",
    "        del z['classification_errors']\n",
    "        del z['party_code']\n",
    "        del z['district_number']\n",
    "        del z['occupancy']\n",
    "        del z['geometric_mean_probability']\n",
    "        del z['log_likelyhood']\n",
    "        del z['latest_congress']\n",
    "        del z['office_attainment_type']\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    mentions_compiled.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['relevant', 'restraining', u'CATEGORICAL_SENTIMENT_DISCLOSURE', 'k_relevant', u'CATEGORICAL_SENTIMENT_JOBS', 'house', 'sex', u'CATEGORY_FOREIGNPOLICY', 'days_since_strike', 'last_name', u'CATEGORICAL_SENTIMENT_REFERENCE', u'CATEGORICAL_SENTIMENT_FOREIGNUSE', 'seniority', u'CATEGORY_PTSD', 'dim_2', 'id', 'dim_1', 'first_name', u'CATEGORY_DISCLOSURE', 'k_sentiment', 'icpsr', 'title', u'CATEGORICAL_SENTIMENT_FOREIGNPOLICY', 'general_sentiment', u'CATEGORICAL_SENTIMENT_PTSD', 'state', u'CATEGORICAL_SENTIMENT_INTERNATIONAL-LEGALITY', 'statement', u'CATEGORICAL_SENTIMENT_FINANCE', 'party', u'CATEGORY_REFERENCE', 'filibuster', u'CATEGORY_INTERNATIONAL-LEGALITY', u'CATEGORICAL_SENTIMENT_DOMESTIC-LEGALITY', u'CATEGORY_HUMANITARIAN', 'congress', 'days_until_term_ends', 'loyalty', u'CATEGORY_JOBS', u'CATEGORY_DOMESTIC-LEGALITY', 'date', 'state_code', 'dronebase', 'categories', u'CATEGORY_FOREIGNUSE', u'CATEGORY_TECHNOLOGY', u'CATEGORY_FINANCE', 'periphery', u'CATEGORICAL_SENTIMENT_TECHNOLOGY', u'CATEGORICAL_SENTIMENT_HUMANITARIAN', 'k_restraining', 'strike_recently', 'votes', 'unsigned_periphery']\n"
     ]
    }
   ],
   "source": [
    "keys = []\n",
    "for z in mentions_compiled:\n",
    "    for key in z.iterkeys():\n",
    "        if key not in keys:\n",
    "            keys.append(key)\n",
    "print keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodecsv as csv\n",
    "with open(\"data_combined.csv\", \"wb\") as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(keys)\n",
    "    for z in mentions_compiled:\n",
    "        if z['relevant'] == z['k_relevant']:\n",
    "            continue\n",
    "        row = []\n",
    "        for key in keys:\n",
    "            if key in z and z[key] != \"Unknown\":\n",
    "                row.append(z[key])\n",
    "            else:\n",
    "                row.append(None)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevance match: 0.701454234388\n",
      "total: 1169.0\n",
      "Kreps relevant: 795\n",
      "relevant: 787\n"
     ]
    }
   ],
   "source": [
    "agreeing_relevance = 0\n",
    "for mention in mentions_compiled:\n",
    "    if mention[\"relevant\"] == mention[\"k_relevant\"]:\n",
    "        agreeing_relevance += 1\n",
    "        \n",
    "total = float(len(mentions_compiled))\n",
    "print \"relevance match: \" + str(agreeing_relevance / total)\n",
    "print \"total: \" + str(total)\n",
    "print \"Kreps relevant: \" + str(len([mention for mention in mentions_compiled if mention[\"k_relevant\"] == 1]))\n",
    "print \"relevant: \" + str(len([mention for mention in mentions_compiled if mention[\"relevant\"] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
